{"cells":[{"cell_type":"markdown","metadata":{"id":"92o35-of6GY6"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_05_seleccion_modelos-published.ipynb)\n","\n","# Selección de modelos"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kSwQbR3r6GY-","executionInfo":{"status":"ok","timestamp":1744839280583,"user_tz":180,"elapsed":1384,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from IPython.display import display\n"]},{"cell_type":"markdown","metadata":{"id":"NG6kINRR6GZA"},"source":["## Cross validation\n","\n","Hasta ahora sólo habíamos visto (ver en el [notebook 03](https://github.com/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_03_arboles_de_decision_sklearn-published.ipynb)) que ibamos a dividir los datos en train y test.\n","\n","\n","En esta semana vimos la opción de hacer validación cruzada. En esta oportunidad lo que haremos será realizar una exploración de hiperparámetros para árboles incorporando conceptos de la clase de esta semana.\n","Vamos a experimentar usando k-fold (con k=10) para explorar distintos valores de configuración de `DecisionTreeClassifier` para seleccionar el hiperparámetro que nos parezca el mejor.\n","Ensayaremos áltura máxima con valores `[None, 1, 2, 3, 5, 8, 13, 21]`.\n","\n","Nos interesará:\n","- controlar el tiempo de entrenamiento\n","- generar alguna métrica que elijamos para seleccionar la áltura máxima\n","\n","Con la mejor configuración obtenida entrenar un clasificador con todos los datos de desarrollo.\n","    \n","Evaluar el comportamiento con el set de evaluación\n","    \n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6OPeQhH6GZB","executionInfo":{"status":"ok","timestamp":1744840889160,"user_tz":180,"elapsed":672,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"126c8bfb-ab34-496a-83af-4fb26608357b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 0.74946762, -1.83875845,  2.31697643, ...,  0.38502105,\n","          1.15910799,  0.36490854],\n","        [ 1.36142303,  0.17739336, -1.06308644, ..., -0.00426734,\n","         -1.63632588, -0.8335227 ],\n","        [ 0.12238178,  1.03817562, -1.46411856, ...,  1.69000604,\n","         -0.57898546,  0.34605186],\n","        ...,\n","        [ 0.77302083,  0.76832206, -0.36434009, ..., -0.05485574,\n","         -0.51528272,  0.7993889 ],\n","        [-0.54238642, -0.87839139,  0.68624112, ...,  0.20799802,\n","          1.06110671, -0.34658297],\n","        [-0.03135099,  0.93928815, -1.16413366, ...,  0.73422269,\n","         -0.37504853, -0.59041732]]),\n"," array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n","        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n","        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n","        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0]))"]},"metadata":{},"execution_count":4}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.tree import DecisionTreeClassifier\n","import timeit\n","import pandas as pd\n","\n","def cargar_datos():\n","  #  df = pd.read_csv('https://github.com/aprendizaje-automatico-dc-uba-ar/material/blob/main/datasets/data_05/seleccion_modelos.csv')\n","   # df = pd.read_csv('seleccion_modelos.csv'\n","    df = pd.read_csv('https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/datasets/data_05/seleccion_modelos.csv')\n","    X = df.drop(\"Y\", axis=1)\n","    y = df.Y\n","    return X.to_numpy(), y.to_numpy()\n","\n","X, y = cargar_datos()\n","X,y"]},{"cell_type":"markdown","metadata":{"id":"IhuGtQrB6GZC"},"source":["Primero separaremos nuestro data set entre **desarrollo** y **evaluación** en un 10%. Para esto podemos usar `train_test_split`"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"FNs0Dj816GZC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744840899715,"user_tz":180,"elapsed":47,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"fb593237-c317-4462-d2a6-a1cf3bbad8e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":5}],"source":["# separamos entre dev y eval\n","X_dev, X_eval, y_dev, y_eval = train_test_split(\n","                    X,\n","                    y,\n","                    random_state=4,\n","                    test_size=0.1)\n","type(y_eval)"]},{"cell_type":"markdown","metadata":{"id":"9eYXaBf46GZD"},"source":["Por el momento dejaremos el set de evaluación de lado y nos manejaremos con el de desarrollo.\n","\n","Pasemos a experimentar los distinos `h_max` posibles.\n","\n","Usaremos estas dos funciones para entrenar un árbol y para usarlo para predecir respectivamente:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"2CsHvAlH6GZD","executionInfo":{"status":"ok","timestamp":1744841036695,"user_tz":180,"elapsed":4,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["def train_tree(X_tr: np.ndarray, y_tr: np.ndarray, tree_params={}) -> DecisionTreeClassifier:\n","    arbol = DecisionTreeClassifier(**tree_params)\n","    arbol.fit(X_tr, y_tr)\n","\n","    return arbol\n","\n","def tree_predict(ab: DecisionTreeClassifier, X_test: np.ndarray) -> np.ndarray:\n","    predictions = ab.predict(X_test)\n","    return predictions"]},{"cell_type":"markdown","metadata":{"id":"HNvN79NV6GZE"},"source":["Y definimos la métrica a usar. A modo de ejemplo figura accuracy.\n","\n","Cambiar la medida por una nueva vista en clase."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SeP4jKtE6GZE","executionInfo":{"status":"ok","timestamp":1744843057626,"user_tz":180,"elapsed":7,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["def accuracy(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n","    TP_TN = sum([y_i == y_j for (y_i, y_j) in zip(y_predicted, y_real)])\n","    P_N = len(y_real)\n","    return TP_TN /P_N\n","\n","def metrica_seleccionada(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n","    return accuracy(y_predicted, y_real)"]},{"cell_type":"markdown","metadata":{"id":"JEplchZZ6GZF"},"source":["Realización del experimento.\n","\n","Nota: se inicializa con una semilla para poder reproducir el resultado."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6ZEkXvdb6GZF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744843060260,"user_tz":180,"elapsed":134,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"4628553e-fa14-4f28-831d-6dfd94b8448b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Órden obtenido según la métrica elegida\n","\t1- h_max=1 con 0.881\n","\t2- h_max=3 con 0.874\n","\t3- h_max=2 con 0.867\n","\t4- h_max=5 con 0.859\n","\t5- h_max=8 con 0.830\n","\t6- h_max=None con 0.822\n","\t7- h_max=13 con 0.800\n","\t8- h_max=21 con 0.800\n"]}],"source":["results = []\n","\n","np.random.seed(44)\n","for h_max in [None, 1, 2, 3, 5, 8, 13, 21]:\n","    kf = KFold(n_splits=10)\n","    y_pred = np.empty(y_dev.shape)\n","    y_pred.fill(np.nan)\n","\n","    # generamos para cada fold una predicción\n","    for train_index, test_index in kf.split(X_dev):\n","\n","        #saco el fold que no uso para entrenar\n","        kf_X_train, kf_X_test = X_dev[train_index], X_dev[test_index]\n","        kf_y_train, kf_y_test = y_dev[train_index], y_dev[test_index]\n","\n","        current_tree = train_tree(kf_X_train, kf_y_train,\n","                                    tree_params={\"max_depth\":h_max})\n","        predictions = tree_predict(current_tree, kf_X_test)\n","        y_pred[test_index] = predictions\n","\n","    current_score = metrica_seleccionada(y_pred, y_dev)\n","\n","    results.append((h_max,current_score))\n","\n","\n","# Ordenamos los resultados (puede ser que convenga del derecho o del reves)\n","r = sorted(results, key=lambda x: x[1], reverse=True)\n","\n","print(\"Órden obtenido según la métrica elegida\")\n","for idx, (h, sc) in enumerate(r):\n","    print(f\"\\t{idx+1}- h_max={h} con {sc:.3f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"eciEBnWw6GZF"},"source":["Con los resultados obtenidos podemos elegir la `h_max` que nos parezca mejor. Con eso vamos a reentrenar el modelo con todos los datos.\n","\n","¿Qué teníamos que tener en cuenta en estos casos?"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"UiaJBxIp6GZF","executionInfo":{"status":"ok","timestamp":1744844201156,"user_tz":180,"elapsed":5,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["# elegimos\n","h_max = 1 # COMPLETAR\n","selection_score = 0.881 # COMPLETAR\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tznfE74K6GZG","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"error","timestamp":1744405729888,"user_tz":180,"elapsed":39,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"7bd627f8-cdba-4f04-a614-ef388c6db2e2"},"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Completar la celda anterior para continuar","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-61c6998da425>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mselection_score\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Completar la celda anterior para continuar\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAssertionError\u001b[0m: Completar la celda anterior para continuar"]}],"source":["assert selection_score is not None, \"Completar la celda anterior para continuar\""]},{"cell_type":"markdown","metadata":{"id":"FRyE7aLT6GZG"},"source":["Con el mejor parámetro entrenamos un nuevo clasificador:"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4k7RS-Hp6GZG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744844205272,"user_tz":180,"elapsed":14,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"5e4359a1-39b0-4909-e1a8-db1371c70585"},"outputs":[{"output_type":"stream","name":"stdout","text":["Construimos nuestro clasificador con parámetro 'max_depth'=1. Para seleccionarlo el score que habíamos obtenido era 0.881\n"]}],"source":["print(f\"Construimos nuestro clasificador con parámetro 'max_depth'={h_max}. \"\n","     + f\"Para seleccionarlo el score que habíamos obtenido era {selection_score:.3f}\")\n","\n","best_tree = train_tree(X_dev, y_dev,\n","                            tree_params={\"max_depth\":h_max})\n"]},{"cell_type":"markdown","metadata":{"id":"ulqfcYH_6GZG"},"source":["Podemos evaluar este árbol en train."]},{"cell_type":"code","execution_count":24,"metadata":{"scrolled":true,"id":"qhmlk-Sz6GZG","executionInfo":{"status":"ok","timestamp":1744844206727,"user_tz":180,"elapsed":7,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["y_pred = tree_predict(best_tree, X_dev)\n","best_tree_score = metrica_seleccionada(y_pred, y_dev)"]},{"cell_type":"markdown","metadata":{"id":"92NZ2tcr6GZH"},"source":["¿Qué nos están diciendo estos dos scores?¿Para qué nos sirven?"]},{"cell_type":"markdown","metadata":{"id":"-YD25DXM6GZH"},"source":["Por única vez vemos como funciona nuestro entrenamiento en los datos de **evaluación** que no habíamos mirado."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"sYx9KduG6GZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744844208974,"user_tz":180,"elapsed":10,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"461d3f28-1c43-4360-daa8-efd778521f45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de 0.733\n"]}],"source":["y_pred_eval = tree_predict(best_tree, X_eval)\n","best_tree_score_eval = metrica_seleccionada(y_pred_eval, y_eval)\n","\n","print(f\"Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de {best_tree_score_eval:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"4Qxzf4bN6GZH"},"source":["*Opcionales*\n","\n","1. Simular qué hubiese ocurrido si hubieramos elegido un K distinto. ¿La diferencia entre el score en *dev* y el score en *eval* cambia significativamente?\n","2. Repetir el mismo ejercicio de elegir la mejor combinación de parametros pero esta vez establecer una grilla donde se exploren al menos dos hiperparámetros que no sean la altura máxima. Revisar la documentación de `DecisionTreeClassifier`, por ejemplo pueden elegir la **medida de impureza** y el **mínimo de muestas necesario para realizar un split**. Definir los rangos necesarios para explorar más de un valor de cada hiperparámetro considerado. ¿Este modelo fue mejor que el obtenido en el punto anterior?\n","\n","**Importante**: en este punto nos tomamos la licencia de usar nuevamente el conjunto de evaluación. El re-uso del conjunto de evaluación sólo lo permitimos en este caso por motivos pedagócios. Pero **NO DEBE** suceder en la práctica.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6K7wXAn96GZH"},"source":["## Group K-Fold\n"]},{"cell_type":"markdown","metadata":{"id":"prPUPakn6GZI"},"source":["Cuando entrenamos modelos de machine learning, nuestro objetivo es evaluar correctamente su capacidad para generalizar a nuevos datos. Para ello, utilizamos técnicas de validación cruzada como K-Fold. Sin embargo, en algunos casos, el uso de K-Fold tradicional puede llevar a una sobreestimación del rendimiento del modelo si no se considera la estructura de los datos.\n","\n","Por ejemplo, si queremos que nuestro modelo sea capaz de predecir emociones en personas que nunca ha visto, pero en los datos de entrenamiento y prueba aparecen instancias de las mismas personas, estaremos evaluando algo distinto a lo que realmente nos interesa. En este caso, deberíamos agrupar las instancias por el atributo `persona_id`.\n","\n","Lo mismo ocurre en problemas médicos: si queremos que el modelo generalice a hospitales nuevos, pero en la validación se mezclan datos del mismo hospital entre el entrenamiento y la prueba, el modelo podría estar aprovechando características específicas de cada hospital en lugar de aprender patrones generales. Para evitarlo, debemos agrupar por `hospital_id`.\n","\n","Utilizar `Group K-Fold` nos permite asegurarnos de que la validación refleje realmente la capacidad del modelo para generalizar, garantizando que los datos de un mismo grupo no aparezcan en ambos conjuntos (entrenamiento y validación). Así, obtenemos una estimación más realista de su desempeño en escenarios del mundo real."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"uBOzb7Ji6GZI","executionInfo":{"status":"ok","timestamp":1744844510337,"user_tz":180,"elapsed":9,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Simulación de datos médicos\n","np.random.seed(42)\n","n_samples = 1000\n","n_patients = 7\n","\n","df = pd.DataFrame({\n","    'biomarker1': np.random.randn(n_samples),\n","    'biomarker2': np.random.randn(n_samples),\n","    'patient_id': np.random.randint(0, n_patients, n_samples),  # Cada paciente tiene múltiples muestras\n","    'disease': np.random.randint(0, 2, n_samples)  # 0 = sano, 1 = enfermo\n","})"]},{"cell_type":"markdown","metadata":{"id":"VPFZwRRP6GZI"},"source":["Veamos cuánto es la estimación si usamos K-fold normal"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"RBgfCAmV6GZI","executionInfo":{"status":"ok","timestamp":1744844595370,"user_tz":180,"elapsed":133,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["results_kfold = []\n","\n","X = df[['biomarker1', 'biomarker2', 'patient_id']].values\n","y = df['disease'].values\n","\n","np.random.seed(44)\n","for h_max in [None, 1, 2, 3, 5, 8, 13, 21]:\n","    kf = KFold(n_splits=5, shuffle=True)\n","    y_pred = np.empty(y.shape)\n","    y_pred.fill(np.nan)\n","\n","    # generamos para cada fold una predicción\n","    for train_index, test_index in kf.split(X):\n","\n","        #saco el fold que no uso para entrenar\n","        kf_X_train, kf_X_test = X[train_index], X[test_index]\n","        kf_y_train, kf_y_test = y[train_index], y[test_index]\n","\n","        current_tree = train_tree(kf_X_train, kf_y_train,\n","                                    tree_params={\"max_depth\":h_max})\n","        predictions = tree_predict(current_tree, kf_X_test)\n","        y_pred[test_index] = predictions\n","\n","    current_score = metrica_seleccionada(y_pred, y)\n","\n","    results_kfold.append((h_max,current_score))"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"s1YRQYA-6GZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744844597254,"user_tz":180,"elapsed":5,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"7fb4ced5-af8c-4bae-c09c-e789047ee0ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(None, np.float64(0.498)),\n"," (1, np.float64(0.511)),\n"," (2, np.float64(0.513)),\n"," (3, np.float64(0.51)),\n"," (5, np.float64(0.493)),\n"," (8, np.float64(0.506)),\n"," (13, np.float64(0.496)),\n"," (21, np.float64(0.471))]"]},"metadata":{},"execution_count":29}],"source":["results_kfold"]},{"cell_type":"markdown","metadata":{"id":"J76Ejz0P6GZI"},"source":["Ahora hagamos el mismo procedimiento pero agrupando por el atributo 'patient_id', considerando que vamos a tener un fold por paciente."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"5X9DQtKo6GZJ","executionInfo":{"status":"ok","timestamp":1744844684376,"user_tz":180,"elapsed":25,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["results_group_kfold = []\n","\n","X = df[['biomarker1', 'biomarker2']].values  # Características sin patient_id\n","y = df['disease'].values\n","groups = df['patient_id'].values  # Usamos patient_id como grupo"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"LJDm4hjN6GZJ","executionInfo":{"status":"ok","timestamp":1744845541809,"user_tz":180,"elapsed":832,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}}},"outputs":[],"source":["# TODO: Implementar Group K-Fold manualmente\n","# 1. Obtener los grupos únicos\n","unique_groups = np.unique(groups) # COMPLETAR\n","\n","# 2. Mezclar los grupos (para aleatorizar)\n","np.random.shuffle(unique_groups)\n","\n","# 3. Dividir los grupos en folds (consideramos un grupo por fold)\n","n_splits = len(unique_groups)\n","group_folds = np.array_split(unique_groups, n_splits)\n","\n","# 4. Para cada profundidad máxima del árbol que quieras evaluar:\n","for h_max in [None, 1, 2, 3, 5, 8, 13, 21]:\n","    # Inicializa el array para guardar las predicciones\n","    y_pred = np.empty(y.shape)\n","    y_pred.fill(np.nan)\n","\n","    # Para cada fold:\n","    for i in range(n_splits):\n","        # TODO: Definir qué grupos van a test y cuáles a train\n","        # ...\n","        test_groups = group_folds[i]\n","        train_groups = np.concatenate(group_folds[:i] + group_folds[i+1:])\n","\n","        # TODO: Obtener los índices de las muestras para cada conjunto\n","        # ...\n","        train_indices = np.where(np.isin(groups, train_groups))[0]\n","        test_indices = np.where(np.isin(groups, test_groups))[0]\n","\n","\n","        # TODO: Separar los datos según los índices\n","        gkf_X_train, gkf_y_train = X[train_indices], y[train_indices]\n","        gkf_X_test = X[test_indices]\n","\n","        current_tree = train_tree(gkf_X_train, gkf_y_train,\n","                                  tree_params={\"max_depth\": h_max})\n","        predictions = tree_predict(current_tree, gkf_X_test)\n","        y_pred[test_indices] = predictions\n","\n","    # Evaluamos el rendimiento global\n","    current_score = metrica_seleccionada(y, y_pred)\n","    results_group_kfold.append((h_max, current_score))"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"HBC7V34e6GZJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744845544646,"user_tz":180,"elapsed":6,"user":{"displayName":"Franco Martinez","userId":"16124399654133599891"}},"outputId":"956fc717-e4e8-46fd-bdaf-79d0acec8b1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(None, np.float64(0.506)),\n"," (1, np.float64(0.519)),\n"," (2, np.float64(0.511)),\n"," (3, np.float64(0.509)),\n"," (5, np.float64(0.512)),\n"," (8, np.float64(0.519)),\n"," (13, np.float64(0.517)),\n"," (21, np.float64(0.505))]"]},"metadata":{},"execution_count":33}],"source":["results_group_kfold"]},{"cell_type":"markdown","metadata":{"id":"Hr3TP8mA6GZJ"},"source":["Si utilizamos validación cruzada K-Fold tradicional para seleccionar y evaluar nuestro modelo en un conjunto de datos donde múltiples muestras provienen de los mismos pacientes, ¿qué ocurriría cuando intentemos predecir con ese modelo en datos de un paciente completamente nuevo? ¿Cuál sería la relación entre la performance estimada durante la validación y la performance real observada en la práctica clínica con pacientes nuevos?"]}],"metadata":{"celltoolbar":"Tags","kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}